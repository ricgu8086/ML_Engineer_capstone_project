{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata: done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.6.14\n",
      "  latest version: 4.8.3\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/conda\n",
      "\n",
      "  added / updated specs:\n",
      "    - xgboost\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    _py-xgboost-mutex-2.0      |            cpu_0           8 KB  conda-forge\n",
      "    ca-certificates-2020.6.20  |       hecda079_0         145 KB  conda-forge\n",
      "    certifi-2020.6.20          |   py36h9f0ad1d_0         151 KB  conda-forge\n",
      "    libxgboost-1.0.2           |       he1b5a44_1         2.8 MB  conda-forge\n",
      "    py-xgboost-1.0.2           |   py36h9f0ad1d_1         2.2 MB  conda-forge\n",
      "    python_abi-3.6             |          1_cp36m           4 KB  conda-forge\n",
      "    xgboost-1.0.2              |   py36h831f99a_1          11 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         5.4 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  _py-xgboost-mutex  conda-forge/linux-64::_py-xgboost-mutex-2.0-cpu_0\n",
      "  libxgboost         conda-forge/linux-64::libxgboost-1.0.2-he1b5a44_1\n",
      "  py-xgboost         conda-forge/linux-64::py-xgboost-1.0.2-py36h9f0ad1d_1\n",
      "  python_abi         conda-forge/linux-64::python_abi-3.6-1_cp36m\n",
      "  xgboost            conda-forge/linux-64::xgboost-1.0.2-py36h831f99a_1\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates                     2019.11.28-hecc5488_0 --> 2020.6.20-hecda079_0\n",
      "  certifi                                 2019.11.28-py36_0 --> 2020.6.20-py36h9f0ad1d_0\n",
      "\n",
      "The following packages will be DOWNGRADED:\n",
      "\n",
      "  scipy                                1.2.1-py36h09a28d5_1 --> 0.19.1-py36_blas_openblas_202\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "py-xgboost-1.0.2     | 2.2 MB    | ##################################### | 100% \n",
      "_py-xgboost-mutex-2. | 8 KB      | ##################################### | 100% \n",
      "libxgboost-1.0.2     | 2.8 MB    | ##################################### | 100% \n",
      "ca-certificates-2020 | 145 KB    | ##################################### | 100% \n",
      "python_abi-3.6       | 4 KB      | ##################################### | 100% \n",
      "xgboost-1.0.2        | 11 KB     | ##################################### | 100% \n",
      "certifi-2020.6.20    | 151 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "! conda install -c conda-forge xgboost --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn==0.23.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/3a/eb8d7bbe28f4787d140bb9df685b7d5bf6115c0e2a969def4027144e98b6/scikit_learn-0.23.1-cp36-cp36m-manylinux1_x86_64.whl (6.8MB)\n",
      "\u001b[K    100% |████████████████████████████████| 6.9MB 5.3MB/s eta 0:00:01    16% |█████▏                          | 1.1MB 11.8MB/s eta 0:00:01    60% |███████████████████▎            | 4.1MB 24.7MB/s eta 0:00:01    78% |█████████████████████████       | 5.3MB 24.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy>=1.13.3 (from scikit-learn==0.23.1)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/16/476826a84d545424084499763248abbbdc73d065168efed9aa71cdf2a7dc/numpy-1.19.0-cp36-cp36m-manylinux1_x86_64.whl (13.5MB)\n",
      "\u001b[K    100% |████████████████████████████████| 13.5MB 2.5MB/s eta 0:00:01   23% |███████▋                        | 3.2MB 22.1MB/s eta 0:00:01    32% |██████████▍                     | 4.4MB 26.1MB/s eta 0:00:01    74% |████████████████████████        | 10.1MB 23.6MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.6/site-packages (from scikit-learn==0.23.1) (0.19.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.6/site-packages (from scikit-learn==0.23.1) (0.11)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn==0.23.1)\n",
      "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
      "\u001b[31mtensorflow 1.3.0 requires tensorflow-tensorboard<0.2.0,>=0.1.0, which is not installed.\u001b[0m\n",
      "Installing collected packages: numpy, threadpoolctl, scikit-learn\n",
      "  Found existing installation: numpy 1.12.1\n",
      "    Uninstalling numpy-1.12.1:\n",
      "      Successfully uninstalled numpy-1.12.1\n",
      "  Found existing installation: scikit-learn 0.19.1\n",
      "    Uninstalling scikit-learn-0.19.1:\n",
      "      Successfully uninstalled scikit-learn-0.19.1\n",
      "Successfully installed numpy-1.19.0 scikit-learn-0.23.1 threadpoolctl-2.1.0\n"
     ]
    }
   ],
   "source": [
    "! pip install 'scikit-learn==0.23.1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scipy\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ab/f9/6eeed6d5cd8dd435bbf105d10d778c2d76de1a5838fdbc315a59fb7fad64/scipy-1.5.1-cp36-cp36m-manylinux1_x86_64.whl (25.9MB)\n",
      "\u001b[K    100% |████████████████████████████████| 25.9MB 1.5MB/s eta 0:00:01  3% |█▎                              | 1.0MB 11.2MB/s eta 0:00:03    10% |███▎                            | 2.7MB 22.8MB/s eta 0:00:02    27% |████████▉                       | 7.1MB 22.9MB/s eta 0:00:01    31% |██████████▏                     | 8.2MB 25.4MB/s eta 0:00:01    45% |██████████████▊                 | 11.9MB 25.7MB/s eta 0:00:01    55% |█████████████████▊              | 14.3MB 24.8MB/s eta 0:00:01    69% |██████████████████████▏         | 17.9MB 23.3MB/s eta 0:00:01    99% |████████████████████████████████| 25.8MB 24.8MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.14.5 in /opt/conda/lib/python3.6/site-packages (from scipy) (1.19.0)\n",
      "Installing collected packages: scipy\n",
      "  Found existing installation: scipy 0.19.1\n",
      "    Uninstalling scipy-0.19.1:\n",
      "      Successfully uninstalled scipy-0.19.1\n",
      "Successfully installed scipy-1.5.1\n"
     ]
    }
   ],
   "source": [
    "! pip install scipy --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load artifacts and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_artifacts = \"preproc_artifacts.pkl\"\n",
    "\n",
    "with open(path_artifacts, 'rb') as fin:\n",
    "    artifacts = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = \"Udacity_MAILOUT_052018_TRAIN_preproc.csv\"\n",
    "path_original_train = \"../../data/Term2/capstone/arvato_data/Udacity_MAILOUT_052018_TRAIN.csv\"\n",
    "path_test = \"Udacity_MAILOUT_052018_TEST_preproc.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(path_train, dtype=artifacts['type_converter'])\n",
    "y_df = pd.read_csv(path_original_train, sep=';', usecols=['RESPONSE'])\n",
    "test_df = pd.read_csv(path_test, dtype=artifacts['type_converter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_df\n",
    "y_train = y_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember to check for \"LNR\" column to avoid overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"LNR\" in x_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_df\n",
    "del y_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the test set has no labels we should split train set into train and validation so we can check for any potential overfittin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how well balanced the problem is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.988372\n",
       "1    0.011628\n",
       "Name: RESPONSE, dtype: float64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train['RESPONSE'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not very good. We will need to tune the loss function to overcome this. \n",
    "\n",
    "Here it is a good tip: https://machinelearningmastery.com/xgboost-for-imbalanced-classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = y_train['RESPONSE'].value_counts()\n",
    "scale_pos_weight = num_samples[0] / num_samples[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = xgboost.XGBClassifier(scale_pos_weight=scale_pos_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And to avoid overfitting: https://machinelearningmastery.com/avoid-overfitting-by-early-stopping-with-xgboost-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_set = [(x_val.values, y_val.values.ravel())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.58232\n",
      "Will train until validation_0-auc hasn't improved in 10 rounds.\n",
      "[1]\tvalidation_0-auc:0.55712\n",
      "[2]\tvalidation_0-auc:0.57525\n",
      "[3]\tvalidation_0-auc:0.56756\n",
      "[4]\tvalidation_0-auc:0.58341\n",
      "[5]\tvalidation_0-auc:0.57625\n",
      "[6]\tvalidation_0-auc:0.57088\n",
      "[7]\tvalidation_0-auc:0.55987\n",
      "[8]\tvalidation_0-auc:0.57297\n",
      "[9]\tvalidation_0-auc:0.56719\n",
      "[10]\tvalidation_0-auc:0.57270\n",
      "[11]\tvalidation_0-auc:0.56332\n",
      "[12]\tvalidation_0-auc:0.56641\n",
      "[13]\tvalidation_0-auc:0.57181\n",
      "[14]\tvalidation_0-auc:0.56978\n",
      "Stopping. Best iteration:\n",
      "[4]\tvalidation_0-auc:0.58341\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = clf.fit(x_train.values, y_train.values.ravel(), \\\n",
    "              early_stopping_rounds=10, eval_metric=\"auc\", eval_set=eval_set, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the logs we noticed that we have a ROC-AUC of 0.583 in validation set. It's not the best score ever, in fact, it is slightly better than predicting by chance, but this is a heavily imbalanced dataset and a much more advanced feature engineering will be required to improve this score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score test partition and prepare Kaggle submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_proba_pred = clf.predict_proba(test_df.drop(columns=['LNR']).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['LNR'] = test_df['LNR'].astype(int)\n",
    "submission['RESPONSE'] = y_test_proba_pred[:,0]\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
